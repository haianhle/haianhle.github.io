<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.46" />
  <meta name="author" content="Anh H. Reynolds">
  <meta name="description" content="Quantum Chemist &amp; Data Scientist">
  <link rel="alternate" hreflang="en-us" href="/">
  <meta name="theme-color" content="#0095eb">
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  <link rel="stylesheet" href="../css/styles.css">
  
  <script type="text/javascript">
  !function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t,e){var n=document.createElement("script");n.type="text/javascript";n.async=!0;n.src="https://cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(n,a);analytics._loadOptions=e};analytics.SNIPPET_VERSION="4.1.0";
  analytics.load("YOUR_WRITE_KEY");
  analytics.page();
  }}();
</script>
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-126274462-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Anh H. Reynolds">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Anh H. Reynolds">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="img/icon-192.png">
  <link rel="canonical" href="/">
  <meta property="twitter:card" content="summary_large_image">
  <meta property="og:site_name" content="Anh H. Reynolds">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Anh H. Reynolds">
  <meta property="og:description" content="Quantum Chemist &amp; Data Scientist">
  <meta property="og:locale" content="en-us">
  <meta property="og:updated_time" content="2017-10-15T00:00:00-04:00">
  

  

<title>Anh H. Reynolds</title>
</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">
    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../index.html">Anh H. Reynolds</a>
    </div>

    
    <div class="collapse navbar-collapse">
      
      <ul class="nav navbar-nav navbar-right">
        <li class="nav-item">
          <a href="../index.html#about" data-target="#about">
            
            <span>Home</span>
            
          </a>
        </li>

        <li class="nav-item">
          <a href="../index.html#blogs" data-target="#blogs">
            
            <span>Blogs</span>
            
          </a>
        </li>

        <li class="nav-item">
          <a href="../index.html#contact" data-target="#contact">
            
            <span>Contact</span>
            
          </a>
        </li>
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>
  
  <section id="about" class="home-section">
    <div class="container">

<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-address">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('../img/anh.jpg');"></div>
      <meta itemprop="image" content="../img/anh.jpg">
      

      <div class="portrait-title">
        <h2 itemprop="name">Anh H. Reynolds</h2>
        <h3 itemprop="jobTitle">Quantum Chemist &amp; Data Scientist</h3>
        
        <!--
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <span itemprop="name">Northwestern University</span>
        </h3>
        -->
      </div>

      <link itemprop="url" href="/">
      <ul class="network-icon" aria-hidden="true">
        <li>
          <a itemprop="sameAs" href="https://linkedin.com/in/anhreynolds" target="_blank" rel="noopener">
            <i class="fa fa-linkedin big-icon"></i>
          </a>
        </li>
        
        <!--
        <li>
          <a itemprop="sameAs" href="https://www.instagram.com/anhle911/" target="_blank" rel="noopener">
            <i class="fa fa-instagram big-icon"></i>
          </a>
        </li>
        -->
        
        <li>
          <a itemprop="sameAs" href="https://github.com/haianhle" target="_blank" rel="noopener">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
        <li>
          <a itemprop="sameAs" href="https://scholar.google.com/citations?user=7xgx7FYAAAAJ&hl=en" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar-square big-icon"></i>
          </a>
        </li>

        <li>
          <a itemprop="sameAs" href="mailto:anh.reynolds@gmail.com" target="_blank" rel="noopener">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">
    
<h1>Recurrent Neural Networks and Language Modelling</h1>

     </br>
     </br>
     An image can catch different people's eyes differently. 
     However, very often, we observe an image, photo,
     or painting as a whole, trying our best to take in its entirety before
     arriving at any conclusion. We do not know
     where the artist started first on his canvas, the process the painting was developed.
     Music, video, and speech, on the other hand, have a temporal dimension that make their data sequential. 
     We process and store information in order. There is a before and after. As a result, traditional neural networks,
     despite its tremendous success in computer vision,
     cannot easily tackle problems related to sequence data.
     </br>
     </br>
     In addition, simple deep neural networks cannot be easily applied to 
     problems in which inputs and outputs cannot be encoded with vectors of fixed dimensionality.
     The lengths of sequence data in speech recognition, machine translation, or question answering,
     for example, are not known <i>a priori</i>.
     <i>"Where are you going"</i> in English (4 words) is translated as <i>"Où est-ce que vous allez"</i> (5 words),
     or <i>"Où allez-vous"</i> (3 words) in French,
     and <i>"Bạn đang đi đâu đấy"</i> in Vietnamese (5 words).
     </br>
     </br>
     The solution to the problems mentioned above is to use a Recurrent Neural Network (RNN), which contains
     a loop that allows inputs from the previous time steps to influence the output produced at the current time step. 
     In other words, RNN uses the knowledge it receives in the past to make predictions about the future, what is coming next.
     </br>
     </br>
     <center><figure>
     <img src="../img/rnn.png" width="35%" class="center"></img>
     </figure></center>
     </br>
     An example of a simple unrolled RNN is shown below, where the lengths of the input sequence \(T_x\) and output sequence \(T_y\) are the same.
     Each training example can contain a different number of "tokens" represented by a series of vectors at different
     time steps \(\{x^{\lt t\gt}\}=x^{\lt 1\gt}, x^{\lt 2\gt}, \dots, x^{\lt T_x\gt}\). For example, a sentence
     <i>"Where are you going"</i> can be represented using a series of 4 one-hot vectors (\(T_x=4\)),
     each represents a word (token) in the sentence,
     over a preset vocabulary.
     </br>
     </br>
     <center><figure>
     <img src="../img/rnn-unrolled.png" width="70%" class="center"></img>
     <figcaption><font size="3">
     An example of a many-to-many unidirectional RNN where the lengths of the
     input and output sequences are the same \(T_x = T_y\)</p>
     </font></figcaption>
     </figure></center>
     </br>
     For one exampale, at each time step \(t\), the activation \(a^{\lt t\gt}\) can be computed using the
     input at that time step \(x^{\lt t\gt}\) and the activation from the previous time step \(a^{\lt t-1\gt}\).
     The activation function used for this is often \(tanh\) activation.
     </br>
     </br>
     $$a^{\lt t\gt} = g(w_{aa}a^{\lt t-1\gt} + w_{ax}x^{\lt t\gt} + b_a)$$
     $$\hat{y}^{\lt t\gt} = g'(w_{ya}a^{\lt t\gt}+b_y)$$
     </br>
     \(a^{\lt t\gt}, x^{\lt t\gt}, \hat{y}^{\lt t\gt}\) are the activation, input, and output
     for one example at time step \(t\).
     The initial activation \(a^{\lt 0\gt}\) is usually initialized to zeros.
     Note how the weights are shared across different time steps. This idea of parameter sharing is
     somewhat similar to that in convolutional neural networks.
     </br>
     </br>
     The loss function can be computed for each time step, for example, for cross-entropy loss:
     $$\mathcal{L}^{\lt t\gt}(\hat{y}^{\lt t\gt}, y^{\lt t\gt})=-y^{\lt t\gt}\log\hat{y}^{\lt t\gt}-(1-y^{\lt t\gt})\log(1-\hat{y}^{\lt t\gt})$$
     </br>
     The loss function for one example is the sum of all the loss functions at each time step: 
     $$\mathcal{L}(\hat{y}, y)=\sum_t\mathcal{L}^{\lt t\gt}(\hat{y}^{\lt t\gt}, y^{\lt t\gt})$$
     </br>
     Other examples of unidirectional RNNs are shown below.
     <center><figure>
     <img src="../img/rnn-many-to-one.png" width="70%" class="center"></img>
     <figcaption><font size="3">
             Many-to-one RNN, for example, in sentiment classification
     </font></figcaption>
     </figure></center>

     <center><figure>
     <img src="../img/rnn-one-to-many.png" width="70%" class="center"></img>
     <figcaption><font size="3">
          One-to-many RNN, for example, in sequence generation
     </font></figcaption>
     </figure></center>

     <center><figure>
     <img src="../img/rnn-many-to-many.png" width="70%" class="center"></img>
     <figcaption><font size="3">
          Many-to-many RNN, for example, in machine translation, where the lengths
          of the input and output sequences are different
     </font></figcaption>
     </figure></center>
     </br>
     </br>
     The last model shown above is an RNN Encoder-Decoder, and is very popular in sequence to sequence
     learning. Basically, two RNNs forming an encoder-decoder pair are used.
     The encoder extracts a fixed length vector representation
     from a variable-length source sequence of symbols, while the decoder generates from this
     fixed length representation a new variable-length target sequence of symbols.
     Examples of such network were proposed by Cho et al. 2014 and Sutskever et al. 2014.
     
     </br>
     </br>
     However, a basic RNN architecture runs into vanishing gradient problem in deep network
     and consequently cannot well capture long-range dependencies, or dependencies that span
     a long interval. Since the review by Bengio et al. in 2013, lots of progress has been made
     to address this problem. Some of these models will be discussed in future posts.
     </br>
     </br>

     <i>(to be continued)</i>
     <h4>References</h4>
     <ul>
         <li>Andrew Ng in Sequence Models, 5th course in the Deep Learning Specialization on Coursera.</li>
         <li>Bengio, Lewandowski, and Pascanu, "Advances in optimizing recurrent networks",
         In Proceedings of the 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2013.</li>
         <li>Cho, van Merrienboer, Gulcehre, Bougares, Schwenk, and Bengio,
         "Learning phrase representations using RNN encoder-decoder for statistical machine translation.",
         in Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP), 2014.
         <li>Sutskever, Vinyals, and Le, "Sequence to sequence learning with neural networks",
         in Advances in Neural Information Processing Systems (NIPS), 2014.</li>
     </ul>
</div>



<footer class="site-footer">
  <div class="container">

    

    <p class="powered-by">

      &copy; 2019 &middot; 
      Anh H. Reynolds 
      

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

    <script src="js/hugo-academic.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  </body>
</html>


