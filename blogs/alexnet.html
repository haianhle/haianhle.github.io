<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>AR::AlexNet</title>
<!--
-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300,400">
    <link rel="stylesheet" href="../css/bootstrap.min.css">
    <link rel="stylesheet" href="../css/magnific-popup.css">
    <link rel="stylesheet" href="../css/ar-style.css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
</head>

<body>
    <div class="container-fluid">
        <section id="welcome" class="tm-content-box tm-banner margin-b-10">
            <div class="tm-banner-inner">
                <h1 class="tm-banner-title"><a href="../index.html" style="text-decoration: None; color:#0d3298"> Anh H. Reynolds</a></h1>
            </div>                    
        </section>
        <!--
        <p align='center' style="font-size:200%;color:#0d3298">Data Science</p>
        -->


        <div class="tm-body">
            <div class="tm-sidebar">
                <nav class="tm-main-nav">
                    <ul class="tm-main-nav-ul">
                        <li class="tm-nav-item"><a href="../index.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>About me</a>
                        </li>
                        <li class="tm-nav-item"><a href="../datascience.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Data Science</a>
                        </li>
                        <li class="tm-nav-item"><a href="../404.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Quantum Chemistry</a>
                        </li>
                        <li class="tm-nav-item"><a href="../cv.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Curriculum Vitae</a>
                        </li>
                        <li class="tm-nav-item"><a href="../others.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Other interests</a>
                        </li>
                    </ul>
                </nav>

            </div>

            <div class="tm-main-content">
                <div class="tm-content-box tm-content-box-home">                        
                    <h2>Large-scale image recognition: AlexNet</h2>
                    <p align="justify">
                    Source:
                    <a href=http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ> original paper</a>
                    by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton (2012)
                    </br>
                    </br>
                    AlexNet refers to an eight-layer convolutional neural network (ConvNet) that was the winner of the 
                    <a href=http://www.image-net.org/challenges/LSVRC/>ILSVRC</a>
                    (ImageNet Large Scale Visual Recognition Competition), the Blackpool for image classification, in 2012,
                    consisting of 5 convolutional layers, 3 fully connected layers with a final 1000-way softmax,
                    amounting to a total of 60 million parameters.
                    The scale of this network was considered very impressive at the time, and was in part possible
                    thanks to the highly optimized implementation of 2D convolution on GPUs. 
                    The network took 5-6 days to be trained on 1.2 million images using
                    2 GTX 580 3GB GPUs, and the authors believed that improvement is possible with simply faster GPUs and bigger
                    datasets. At the time, the model was parallelized such that the GPUs communicate only in certain layers, which
                    consequently lowered their error rates by 1â€“2%.
                    ReLU (instead of \(tanh\)) activation function was used to speed up learning.
                    Dropout regularization was used to reduce overfitting in the fully connected layers.
                    Data augmentation was used to artificially increase the size of the dataset and as a result reduce overfitting.
                    This was done either through image translations and horizontal reflections by
                    extracting random patches and their horizontal reflections from the resized images, 
                    or through altering the intensities of the RGB channels in training images.

                    The paper reported results, including top-1 and top-5 error rates, on the ILSVRC-2010 
                    and ILSVRC-2012 dataset.
                    </p>
                    </br>
                    <h4> The model</h4>
                    <p align="justify">
                    The images from the dataset are resized to be \(256 \times 256\), non-squared images are cropped first.
                    The RGB values for each pixels are normalized using the mean of the training set.
                    The architechture of the model is shown below.
                    </p>
                    </br>
                    <center><img src="alexnet.png" width="100%" class="center"></img></center>
                    </br>
                    <p align="justify">
                    As mentioned previously, data augmentation was used to artificially enlarge the size
                    of the data set. One form of data augmentation used in the model was done by extracting
                    random \(224\times 224\times 3\) patches from the \(256\times 256\) images. 
                    These patches then go through 5 convolutional layers and 3 fully connected layers.
                    Notice that there is likely a mistake here in the paper and the patches' dimensions 
                    should be \(227\times 227\times 3\), as pointed out by Andrew Ng and others.
                    <ul align="justify">
                        <li><p>1st convolutional layer: 96 kernels
                        of size \(11\times 11\times 3\) and a stride of 4 pixels, followed by
                        a max pooling layer of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(55\times 55\times 96\) after Conv 1,
                        and \(27\times 27\times 96\) after Pool 1.
                        </li></p>
                        <li><p>2nd convolutional layer: same convolution with 256 kernels of size 
                        \(5\times 5\times 96\) and a stride of 1, followed by a max pooling layer
                        of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(27\times 27\times 256\) after Conv 2 (\(p=2)\),
                        and \(13\times 13\times 256\) after Pool 2.
                        </li></p>
                        <li><p>3rd convolutional layer: same convolution with 384 kernels of size 
                        \(3\times 3\times 256\), and  a stride of 1, no pooling.
                        Dimensions of the output are \(13\times 13\times 384\) after Conv 3 (\(p=1)\).
                        </li></p>
                        <li><p>4th convolutional layer: same convolution again with 384 kernels 
                        of size \(3\times 3\times 384\), and a stride of 1, no pooling.
                        Dimensions of the output are \(13\times 13\times 384\) after Conv 4 (\(p=1)\).
                        </li></p>
                        <li><p>5th convolutional layer: same convolution again with 256 kernels 
                        of size \(3\times 3\times 384\) and a stride of 1, followed by
                        a max pooling layer of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(13\times 13\times 256\) after Conv 5 (\(p=1)\),
                        and \(6\times 6\times 256\) after Pool 5.
                        </li></p>
                        <li><p> 6th and 7th layers are fully connected layers, each has 4096 neurons
                        </li></p>
                        <li><p> 8th and also last layer is a 1000-way softmax.  </li></p>
                    </ul>
                    <p align="justify">
                    The activation shapes and sizes as well as the number of parameters for each layer
                    are tabulated below. The total number of parameters is calculated to be 62,369,155.
                    </p>
                    </br>
                    <center><img src="alexnet-parameters.png" width="75%" class="center"></img></center> 
                    </br>
                    <p align="justify">
                    The model was trained using stochastic gradient descent with momentum on 
                    mini-batches size 128 examples. The values for momentum parameter used was 0.9 and
                    a weight decay of 0.0005.
                    $$ v_{i+1} := 0.9v_i - 0.0005\times\epsilon\times w_i
                                         - \epsilon\times\langle\frac{\partial L}{\partial w}|_{w_i}\rangle_{D_i}$$
                    $$ w_{i+1} := w_i + v_{i+1}$$
                    where \(i\) is the iteration index, \(v\) is the momentum variable (velocity),
                    \(\epsilon\) is the learning rate, which is the same for all layers and was
                    adjusted manually throughout training based on how the validation error improved,
                    starting at 0.01.
                    The weights \(w\) were initialized from a zero-mean Gaussian distribution
                    with standard deviation 0.01.
                    \(\langle\frac{\partial L}{\partial w}|_{w_i}\rangle_{D_i}\) is the
                    average over the \(i\)th batch \(D_i\) of the derivative of the loss function
                    with respect to \(w\) evaluated at \(w_i\).
                    The biases were initialized to 1 in the 2nd, 4th, and 5th convolutional layers as well
                    as the fully connected layers in order to accelerate the early stages
                    of learning by providing the ReLUs with positive inputs. 
                    The biases in other layers were initialized to 0.
                    </p>
                </div>
            </div>
        </div>

        <footer class="tm-footer">
            <p class="text-xs-center">Copyright &copy; 2019 Anh H. Reynolds</p>
        </footer>

    </div>

    <!-- load JS files -->
    
    <script src="../js/jquery-1.11.3.min.js"></script>
    <script src="https://www.atlasestateagents.co.uk/javascript/tether.min.js"></script> 
    <script src="../js/jquery.magnific-popup.min.js"></script>
    <script src="../js/jquery.singlePageNav.min.js"></script>
    <script src="../js/vendor/modernizr-3.7.1.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery-3.3.1.min.js"><\/script>')</script>
    <script src="../js/plugins.js"></script>
    <script src="../js/main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <!-- Templatemo scripts -->
    <script>  

    function setNavbar() {
        if ($(document).scrollTop() > 160) {
            $('.tm-sidebar').addClass('sticky');
        } else {
            $('.tm-sidebar').removeClass('sticky');
        }
    }                   

    $(document).ready(function(){
        
        // Single page nav
        $('.tm-main-nav').singlePageNav({
            'currentClass' : "active",
            offset : 20
        });

        // Detect window scroll and change navbar
        setNavbar();
        
        $(window).scroll(function() {
          setNavbar();
        });

        // Magnific pop up
        $('.tm-gallery').magnificPopup({
          delegate: 'a', // child items selector, by clicking on it popup will open
          type: 'image',
          gallery: {enabled:true}
          // other options
        });
    });

    </script>             

</body>
</html>
