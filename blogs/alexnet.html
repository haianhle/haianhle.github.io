<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>AR::AlexNet</title>
<!--
-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300,400">
    <link rel="stylesheet" href="../css/bootstrap.min.css">
    <link rel="stylesheet" href="../css/magnific-popup.css">
    <link rel="stylesheet" href="../css/ar-style.css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
</head>

<body>
    <div class="container-fluid">
        <section id="welcome" class="tm-content-box tm-banner margin-b-10">
            <div class="tm-banner-inner">
                <h1 class="tm-banner-title"><a href="../index.html" style="text-decoration: None; color:#0d3298"> Anh H. Reynolds</a></h1>
            </div>                    
        </section>
        <!--
        <p align='center' style="font-size:200%;color:#0d3298">Data Science</p>
        -->


        <div class="tm-body">
            <div class="tm-sidebar">
                <nav class="tm-main-nav">
                    <ul class="tm-main-nav-ul">
                        <li class="tm-nav-item"><a href="../datascience.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Data Science</a>
                        </li>
                        <li class="tm-nav-item"><a href="../404.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Quantum Chemistry</a>
                        </li>
                        <li class="tm-nav-item"><a href="../index.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>About me</a>
                        </li>
                        <li class="tm-nav-item"><a href="../cv.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Curriculum Vitae</a>
                        </li>
                        <li class="tm-nav-item"><a href="../others.html" class="tm-nav-item-link tm-button">
                            <i class="fa tm-nav-fa"></i>Other interests</a>
                        </li>
                    </ul>
                </nav>

            </div>

            <div class="tm-main-content">
                <div class="tm-content-box tm-content-box-home">                        
                    <h2>Large-scale image recognition: AlexNet</h2>
                    <p align="justify">
                    Source:
                    <a href=http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ> original paper</a>
                    by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton (2012)
                    </br>
                    </br>
                    AlexNet refers to an eight-layer convolutional neural network (ConvNet) that was the winner of the 
                    <a href=http://www.image-net.org/challenges/LSVRC/>ILSVRC</a>
                    (ImageNet Large Scale Visual Recognition Competition), the Blackpool for image classification, in 2012,
                    consisting of 5 convolutional layers, 3 fully connected layers with a final 1000-way softmax,
                    amounting to a total of 60 million parameters.
                    The scale of this network was considered very impressive at the time, and was in part possible
                    thanks to the highly optimized implementation of 2D convolution on GPUs. 
                    The network took 5-6 days to be trained on 
                    2 GTX 580 3GB GPUs, and the authors believed that improvement is possible with simply faster GPUs and bigger
                    datasets. At the time, the model was parallelized such that the GPUs communicate only in certain layers, which
                    consequently lowered their error rates by 1â€“2%.
                    ReLU (instead of \(tanh\)) activation function was used to speed up learning.
                    Dropout regularization was used to reduce overfitting in the fully connected layers.
                    Data augmentation was used to artificially increase the size of the dataset and as a result reduce overfitting.
                    This was done either through image translations and horizontal reflections by
                    extracting random patches and their horizontal reflections from the resized images, 
                    or through altering the intensities of the RGB channels in training images.

                    The paper reported results, including top-1 and top-5 error rates, on the ILSVRC-2010 dataset.
                    </p>
                    </br>
                    <h4> The model</h4>
                    <p align="justify">
                    The images from the dataset are resized to be \(256 \times 256\), non-squared images are cropped first.
                    The RGB values for each pixels are normalized using the mean of the training set.
                    </br>
                    </br>
                    The architechture of the model is shown below (the figure is taken from the original paper, but I will make a
                    prettier one when I have time). 
                    </p>
                    <img src="alexnet-fig1.png"></img>
                    </br>
                    
                    <p align="justify">
                    As mentioned previously, data augmentation was used to artificially enlarge the size
                    of the data set. One form of data augmentation used in the model was done by extracting
                    random \(224\times 224\times 3\) patches from the \(256\times 256\) images. 
                    These patches then go through 5 convolutional layers and 3 fully connected layers.
                    There might have been a mistake here in the paper and the patch's dimensions are 
                    supposed to be \(227\times 227\times 3\).
                    <ul align="justify">
                        <li><p>1st convolutional layer: 96 kernels
                        of size \(11\times 11\times 3\) and a stride of 4 pixels, followed by
                        a max pooling layer of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(55\times 55\times 96\) after Conv 1,
                        and \(27\times 27\times 96\) after Pool 1.
                        </li></p>
                        <li>2nd convolutional layer: 256 kernels of size 
                        \(5\times 5\times 48\) and a stride of 1, followed by a max pooling layer
                        of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(51\times 51\times 256\) after Conv 2, and
                        \(11\times 11\times 256\) after Pool 2.
                        </li></p>
                        <li>3rd convolutional layer: 384 kernels of size \(3\times 3\times 256\), and 
                        a stride of 1, no pooling.
                        Dimensions of the output are \(9\times 9\times 384\) after Conv 3.
                        </li></p>
                        <li>4th convolutional layer: 384 kernels of size \(3\times 3\times 192\),
                        and a stride of 1, no pooling.
                        Dimensions of the output are \(7\times 7\times 384\) after Conv 4.
                        </li></p>
                        <li>5th convolutional layer: 256 kernels of size \(3\times 3\times 192\),
                        and a stride of 1, again no pooling.
                        Dimensions of the output are \(5\times 5\times 256\) after Conv 5.
                        </li></p>
                    </ul>
                    <p align="justify">
                    The fully connected layers have 4096 neurons each.
                    ....
                    <h4>Results</h4>
                    <h4>Beyond the paper</h4>
                    <i>(to be continued)</i>
                    </p>
                </div>
            </div>
        </div>

        <footer class="tm-footer">
            <p class="text-xs-center">Copyright &copy; 2019 Anh H. Reynolds</p>
        </footer>

    </div>

    <!-- load JS files -->
    
    <script src="../js/jquery-1.11.3.min.js"></script>
    <script src="https://www.atlasestateagents.co.uk/javascript/tether.min.js"></script> 
    <script src="../js/jquery.magnific-popup.min.js"></script>
    <script src="../js/jquery.singlePageNav.min.js"></script>
    <script src="../js/vendor/modernizr-3.7.1.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery-3.3.1.min.js"><\/script>')</script>
    <script src="../js/plugins.js"></script>
    <script src="../js/main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <!-- Templatemo scripts -->
    <script>  

    function setNavbar() {
        if ($(document).scrollTop() > 160) {
            $('.tm-sidebar').addClass('sticky');
        } else {
            $('.tm-sidebar').removeClass('sticky');
        }
    }                   

    $(document).ready(function(){
        
        // Single page nav
        $('.tm-main-nav').singlePageNav({
            'currentClass' : "active",
            offset : 20
        });

        // Detect window scroll and change navbar
        setNavbar();
        
        $(window).scroll(function() {
          setNavbar();
        });

        // Magnific pop up
        $('.tm-gallery').magnificPopup({
          delegate: 'a', // child items selector, by clicking on it popup will open
          type: 'image',
          gallery: {enabled:true}
          // other options
        });
    });

    </script>             

</body>
</html>
