<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.46" />
  <meta name="author" content="Anh H. Reynolds">
  <meta name="description" content="Physical/Analytical Chemist">
  <link rel="alternate" hreflang="en-us" href="/">
  <meta name="theme-color" content="#0095eb">
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  <link rel="stylesheet" href="../css/styles.css">
  
  <script type="text/javascript">
  !function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t,e){var n=document.createElement("script");n.type="text/javascript";n.async=!0;n.src="https://cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(n,a);analytics._loadOptions=e};analytics.SNIPPET_VERSION="4.1.0";
  analytics.load("YOUR_WRITE_KEY");
  analytics.page();
  }}();
</script>
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-126274462-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Anh H. Reynolds">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Anh H. Reynolds">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="img/icon-192.png">
  <link rel="canonical" href="/">
  <meta property="twitter:card" content="summary_large_image">
  <meta property="og:site_name" content="Anh H. Reynolds">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Anh H. Reynolds">
  <meta property="og:description" content="Physical/Analytical Chemist">
  <meta property="og:locale" content="en-us">
  <meta property="og:updated_time" content="2017-10-15T00:00:00-04:00">
  

  

<title>Anh H. Reynolds</title>
</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">
    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../index.html">Anh H. Reynolds</a>
    </div>

    
    <div class="collapse navbar-collapse">
      
      <ul class="nav navbar-nav navbar-right">
        <li class="nav-item">
          <a href="../index.html#about" data-target="#about">
            
            <span>Home</span>
            
          </a>
        </li>

        <li class="nav-item">
          <a href="../index.html#blogs" data-target="#blogs">
            
            <span>Blogs</span>
            
          </a>
        </li>

        <li class="nav-item">
          <a href="../index.html#contact" data-target="#contact">
            
            <span>Contact</span>
            
          </a>
        </li>
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>
  
  <section id="about" class="home-section">
    <div class="container">

<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-address">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('../img/anh.jpg');"></div>
      <meta itemprop="image" content="../img/anh.jpg">
      

      <div class="portrait-title">
        <h2 itemprop="name">Anh H. Reynolds</h2>
        <h3 itemprop="jobTitle">Physical/Analytical Chemist</h3>
        
        <!--
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <span itemprop="name">Northwestern University</span>
        </h3>
        -->
      </div>

      <link itemprop="url" href="/">
      <ul class="network-icon" aria-hidden="true">
        <li>
          <a itemprop="sameAs" href="https://linkedin.com/in/anhreynolds" target="_blank" rel="noopener">
            <i class="fa fa-linkedin big-icon"></i>
          </a>
        </li>
        
        <!--
        <li>
          <a itemprop="sameAs" href="https://www.instagram.com/anhle911/" target="_blank" rel="noopener">
            <i class="fa fa-instagram big-icon"></i>
          </a>
        </li>
        -->
        
        <li>
          <a itemprop="sameAs" href="https://github.com/haianhle" target="_blank" rel="noopener">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
        <li>
          <a itemprop="sameAs" href="https://scholar.google.com/citations?user=7xgx7FYAAAAJ&hl=en" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar-square big-icon"></i>
          </a>
        </li>

        <li>
          <a itemprop="sameAs" href="mailto:anh.reynolds@gmail.com" target="_blank" rel="noopener">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">
    
                    <h1>Large-scale image recognition: AlexNet</h1>
                    </br>
                    </br>
                    
                    Source:
                    <a href=http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networ> original paper</a>
                    by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton (2012)
                    </br>
                    </br>
                    AlexNet refers to an eight-layer <a href="cnn.html">convolutional neural network</a> (ConvNet) that was the winner of the 
                    <a href=http://www.image-net.org/challenges/LSVRC/>ILSVRC</a>
                    (ImageNet Large Scale Visual Recognition Competition), the Blackpool for image classification, in 2012,
                    consisting of 5 convolutional layers, 3 fully connected layers with a final 1000-way softmax,
                    amounting to a total of 60 million parameters.
                    The scale of this network was considered very impressive at the time, and was in part possible
                    thanks to the highly optimized implementation of 2D convolution on GPUs. 
                    The network took 5-6 days to be trained on 1.2 million images using
                    2 GTX 580 3GB GPUs, and the authors believed that improvement is possible with simply faster GPUs and bigger
                    datasets. At the time, the model was parallelized such that the GPUs communicate only in certain layers, which
                    consequently lowered their error rates by 1â€“2%.
                    ReLU (instead of \(tanh\)) activation function was used to speed up learning.
                    Dropout regularization was used to reduce overfitting in the fully connected layers.
                    Data augmentation was used to artificially increase the size of the dataset and as a result reduce overfitting.
                    This was done either through image translations and horizontal reflections by
                    extracting random patches and their horizontal reflections from the resized images, 
                    or through altering the intensities of the RGB channels in training images.

                    The paper reported results, including top-1 and top-5 error rates, on the ILSVRC-2010 
                    and ILSVRC-2012 dataset.
                    </br>
                    
                    </br>
                    <h4> The model</h4>
                    
                    The images from the dataset are resized to be \(256 \times 256\), non-squared images are cropped first.
                    The RGB values for each pixels are normalized using the mean of the training set.
                    The architechture of the model is shown below.
                    
                    </br>
                    <center><img src="../img/alexnet.png" width="100%" class="center"></img></center>
                    </br>
                    
                    As mentioned previously, data augmentation was used to artificially enlarge the size
                    of the data set. One form of data augmentation used in the model was done by extracting
                    random \(224\times 224\times 3\) patches from the \(256\times 256\) images. 
                    These patches then go through 5 convolutional layers and 3 fully connected layers.
                    Notice that there is likely a mistake here in the paper and the patches' dimensions 
                    should be \(227\times 227\times 3\), as pointed out by Andrew Ng and others.
                    </br>
                    </br>
                    <ul>
                        <li>1st convolutional layer: 96 kernels
                        of size \(11\times 11\times 3\) and a stride of 4 pixels, followed by
                        a max pooling layer of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(55\times 55\times 96\) after Conv 1,
                        and \(27\times 27\times 96\) after Pool 1.
                        </li>
                        <li>2nd convolutional layer: same convolution with 256 kernels of size 
                        \(5\times 5\times 96\) and a stride of 1, followed by a max pooling layer
                        of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(27\times 27\times 256\) after Conv 2 (\(p=2)\),
                        and \(13\times 13\times 256\) after Pool 2.
                        </li>
                        <li>3rd convolutional layer: same convolution with 384 kernels of size 
                        \(3\times 3\times 256\), and  a stride of 1, no pooling.
                        Dimensions of the output are \(13\times 13\times 384\) after Conv 3 (\(p=1)\).
                        </li>
                        <li>4th convolutional layer: same convolution again with 384 kernels 
                        of size \(3\times 3\times 384\), and a stride of 1, no pooling.
                        Dimensions of the output are \(13\times 13\times 384\) after Conv 4 (\(p=1)\).
                        </li>
                        <li>5th convolutional layer: same convolution again with 256 kernels 
                        of size \(3\times 3\times 384\) and a stride of 1, followed by
                        a max pooling layer of size \(3\times 3\) and a stride of 2.
                        Dimensions of the output are \(13\times 13\times 256\) after Conv 5 (\(p=1)\),
                        and \(6\times 6\times 256\) after Pool 5.
                        </li>
                        <li> 6th and 7th layers are fully connected layers, each has 4096 neurons
                        </li>
                        <li> 8th and also last layer is a 1000-way softmax.  </li>
                    </ul>
                    
                    The activation shapes and sizes as well as the number of parameters for each layer
                    are tabulated below. The total number of parameters is calculated to be 62,369,155.
                    
                    </br>
                    <center><img src="../img/alexnet-parameters.png" width="75%" class="center"></img></center> 
                    </br>
                    
                    The model was trained using stochastic gradient descent with momentum on 
                    mini-batches size 128 examples. The values for momentum parameter used was 0.9 and
                    a weight decay of 0.0005.
                    $$ v_{i+1} := 0.9v_i - 0.0005\times\epsilon\times w_i
                                         - \epsilon\times\langle\frac{\partial L}{\partial w}|_{w_i}\rangle_{D_i}$$
                    $$ w_{i+1} := w_i + v_{i+1}$$
                    where \(i\) is the iteration index, \(v\) is the momentum variable (velocity),
                    \(\epsilon\) is the learning rate, which is the same for all layers and was
                    adjusted manually throughout training based on how the validation error improved,
                    starting at 0.01.
                    The weights \(w\) were initialized from a zero-mean Gaussian distribution
                    with standard deviation 0.01.
                    \(\langle\frac{\partial L}{\partial w}|_{w_i}\rangle_{D_i}\) is the
                    average over the \(i\)th batch \(D_i\) of the derivative of the loss function
                    with respect to \(w\) evaluated at \(w_i\).
                    The biases were initialized to 1 in the 2nd, 4th, and 5th convolutional layers as well
                    as the fully connected layers in order to accelerate the early stages
                    of learning by providing the ReLUs with positive inputs. 
                    The biases in other layers were initialized to 0.
                    </br>
                    </br>
</div>



<footer class="site-footer">
  <div class="container">

    

    <p class="powered-by">

      &copy; 2022 &middot;
      Anh H. Reynolds 
      

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

    <script src="js/hugo-academic.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  </body>
</html>


